\section{Methodology}

In this section, we present the DNS dataset and active scanning setup to assess the prevalence of non-secure dynamic configurations used in two global measurement campaigns.

\subsection{DNS data \label{sec:dataset}}

%We used DNS data from four complementary sources: %observed between January 2015 and June 2016 for the first campaign and until December 2016 for the second campaign.
%It consist of 
To make a DNS dynamic update a requestor needs to know the domain name and its authoritative name server.
Therefore, we first  leveraged \texttt{A} and \texttt{NS} RRs for all domains observed in three complementary datasets: Farsight's DNSDB--a large database of passively observed DNS queries fed by hundreds of sensors across the world \cite{dnsdb}, Censys's Internet-Wide Scan Data Repository--collected though DNS requests made with record type \texttt{ANY} \cite{scansio}, and available zone files. 
We obtained  the \url{.com}, \url{.net} and \url{.name} zone files from Verisign \cite{verisign}. 
We also performed zone transfers to replicate DNS databases of the \url{.nl} zone file under the contract of SIDN--the \url{.nl} ccTLD registry \cite{sidn} and \texttt{AXFR} transfers of \url{.se} and \url{.nu} ccTLD \cite{se}. Finally, we collected zone files from the \url{.us} ccTLD, \url{.biz}, \url{.org}, \url{.asia}, \url{.info}, \url{.mobi}, \url{.post} and \url{.tel} legacy gTLDs and 1230 new gTLDs made available by ICANN through the Centralized Zone Data Service \cite{icann-czds}. We enriched the dataset with domains listed in Alexa Top 1M Global Sites \cite{alexa}. The data was gathered between January 2015 and November 2016. We provide a detailed overview of collection periods in the Appendix.
 The long period of observation and the fact that DNSDB may contain entries that are poisoned \cite{Dagon}, means that we expected a lot of records to be obsolete or incorrect, but we aimed at creating a possibly complete overview of the global domain space, while minimizing active measurements.

For the purpose of two global campaigns (\textit{Global 1} and \textit{Global 2}),
we extracted second-level domain names  (and upper-level domains if a given registry provides such registrations, e.g. \url{example.co.uk}), their name servers and IP addresses of name servers. 
For the third campaign (\textit{Subdomains}) we enumerated subdomains and their NS servers as we expected to observe cases of vulnerable subdomains if they were delegated to misconfigured authoritative name servers.
We then performed active measurements to obtain missing data if for a given domain, authoritative server was not passively observed in DNSDB or if in zone files, DNS glue records were missing.
We then excluded invalid domains or domains that resolved to the special ICANN's IP addresses 127.0.53.53 indicating a name collision occurrence \cite{127}, % and raising an alert of a potential issue \cite{127}, 
all \url{.arpa} domains, domains resolving to IP addresses of private networks or invalid IP addresses, and domains/IP addresses of networks managed by administrators that contacted us in the past to exclude them from Internet-wide measurements. 
We also removed all \texttt{NS} RRs for which name servers were listed on the Alexa Top 1M % as popular websites 
(e.g. \texttt{example.com NS google.com}) as we suspected that those represent malicious resolutions \cite{Dagon,wild}.
%
%
For the total 327 M, 353 M, and 35 M unique domains in the aggregated datasets (cf. Table \ref{tab:data}), we enumerated all combinations of the corresponding name servers and their IP addresses, and finally created three ``hitlists'' of \textit{$<$domain, NS IP address$>$} pairs, which were further used in three measurement campaigns. 



\begin{table}
  \caption{Summary of the aggregated DNS data \label{tab:data}}
 \centering
\begin{tabular}{l*{3}{c}r}
\Xhline{2\arrayrulewidth}
\#  & \textbf{\textit{Global 1}} & \textbf{\textit{Global 2}} & \textbf{\textit{Subdomains}}\\
\hline
Domains & 327,688,011 & 353,870,510 & 35,382,217 \\
NS (IP addresses) & 3,448,272 & 3,855,615 & 722,989 \\
Domain--NS IP pairs & 3,277,097,568 & 5,032,117,394 & 104,955,041\\
\Xhline{2\arrayrulewidth}
 \end{tabular}
\end{table}




\subsection{Active scans}

In order to test for the vulnerable setup, we have developed a scanner capable of sending DNS dynamic updates as defined in the relevant RFC 2136~\cite{rfc2136}.
The scanner makes an attempt to add a new \texttt{A} RR to the zone file, associating a new subdomain with the IP address of our web server.
The former is composed of an existing domain name and an additional suffix, i.e. \url{research}.
If a given domain name is \url{onlineshopping.com} then the scanner will try to add \url{research.onlineshopping.com}.
On our web server we host a website that describes the project, the problem of non-secure DNS dynamic updates and necessary steps to correctly configure the two most vulnerable configurations (Microsoft DNS and BIND). 
Finally, it also provides the possibility to opt-out mechanism from further scans. 
%
Once the DNS dynamic update is sent, we first verify if a given zone file is vulnerable by analyzing server's response to an update.
Upon receiving an \texttt{UDPATE} request, a server may signal \texttt{FORMERR} or \texttt{NOTIMP} when the request is not recognized or not implemented. 
If a hardware error or an out-of-memory condition takes place, the server sends back \texttt{SERVFAIL} and restores the zone to its state before this transaction \cite{rfc2136}.
The \texttt{REFUSED} response means that the server refuses to perform the operation for security or policy reasons, whereas \texttt{NOERROR} message may indicate a successful update.
To undoubtedly confirm a vulnerability we perform an active DNS lookup to resolve the subdomain to our web serverâ€™s IP address. 
If this succeeds, then the vulnerability is present. 
Finally, we remove the test DNS record by sending a \textit{delete} request and then try to resolve it again to confirm the removal.

\subsection{Ethical considerations}
